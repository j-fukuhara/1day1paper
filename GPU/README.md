# A Symbolic Emulator for Shuffle Synthesis on the NVIDIA PTX Code
  * K. Matsumura et al.
  * [ACM Compiler Construction 2023 (CC 2023)](https://doi.org/10.1145/3578360.3580253)

## Abstract
  * **OpenACC**などのディレクティブベースのプログラミングモデルは，GPUを使った並列計算を容易にしている．
  * しかし，そうした抽象的なモデルは，プログラマがGPUの機能を利用した低レベルな最適化を行うことを妨げる．
  * これは，実際に生成される計算は，プログラマから隠されるからである．
  * 本論文では，コンパイルの最後に，コードエミュレータフェーズを加える柔軟な最適化手法を提案する
  * 提案手法は，記号解析（symbolic analysis）を使用して，生成されたコードをエミュレートし，**動的な情報**を代わりに用いることで、**さらに低レベルのコード最適化**を適用できるようにする．
  * フロントエンドとして，**CUDA**とOpenACCをサポートし，OpenAccに対しては以前は不可能だった低レベルのGPU最適化を適用することが可能になった．
  * 熟練のGPUプログラマにとっても使うのが難しいwarpレベルのシャッフル命令を自動化することで，提案ツールの能力を示す．
  * ベンチマークと複雑なアプリケーションコードで提案ツールを評価し，4世代のGPUアーキテクチャにおけるシャッフル命令の利点を評価するための詳細な調査を示す．
  
---

# A Compiler Framework for Optimizing Dynamic Parallelism on GPUs
  * M. G. Olabi et al.
  * [IEEE/ACM Code Generation and Optimization 2022 (CGO 2022)](https://doi.org/10.1109/CGO53902.2022.9741284)

## Abstract
  * GPUにおける**Dynamic Parallelism**（動的並列性）は，スレッドが動的に他のスレッドを起動（launch）するものである．
  * これは，並列性がネストしているアプリケーションでは有用である．
  * 特に，ネストしている並列性の程度が不規則で，事前に予測できない場合に有用である．
  * しかし，これまでの研究では，多くの小さなグリッドが起動されると，動的な並列性がパフォーマンスを低下させる可能性があることが示されている．
  * 起動の数が多いと，その過密性によって起動のレイテンシが長くなり，グリッドサイズが小さいと，ハードウェアリソースが十分に活用されないという問題がある．
  * この問題を解決するために，ネストしている並列性を持つアプリケーションにおける動的並列性を最適化するコンパイラフレームワークを提案する．
  * このフレームワークは，次の３つの最適化から成る：thresholding, coarsening, aggregation．
  * **thresholding**は，子スレッドの数がある閾値を超えたときのみ動的にグリッドを起動し，それ以外の場合には親スレッドと子スレッドを連続に並べる（serializing）．
  * **coarsening**は，単一の大きなスレッドブロックによって，複数のスレッドブロックの作業を実行して，それら全体で共通の作業を償却する．
  * **aggregation**は，複数の子グリッドを単一のグリッドに集める．
  * thresholdingはプログラマによって手動で行われることもあるが，我々はコンパイラで自動化した．
  * coarseningは他の最適化として，適用されることもあるが，我々は動的並列性のためにcoarseningを適用し，それをコンパイラで自動化した．
  * aggregationは先行研究で既に自動化されているが，我々の手法は，複数のスレッドブロックの粒度でaggregationを行う新しいものである．
  * 我々はこの３つの最適化をオープンソースコンパイラフレームワークに統合した．
  * 実験では，ネストしている並列性を持つアプリケーションにおいて，動的並列性を用いるものでパフォーマンスを幾何平均で43倍，動的並列性を用いないもので8.7倍，aggregationとともに動的並列性を用いるもので3.6倍改善した．